
Tue Oct 17 19:19:16 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  | 00000000:32:00.0 Off |                  Off |
| N/A   29C    P0              49W / 400W |      4MiB / 40960MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA A100-SXM4-40GB          On  | 00000000:E3:00.0 Off |                  Off |
| N/A   30C    P0              49W / 400W |      4MiB / 40960MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
/gpfs/home3/drau/llm_rankers/venv/lib/python3.9/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: CUDA driver initialization failed, you might not have a CUDA gpu. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)
  return torch._C._cuda_getDeviceCount() > 0
- - - - - - - - - -  Quantization and Flash Attention  2.0 not used! - - - - - - - - - - 
Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]Loading checkpoint shards:   7%|▋         | 1/15 [00:01<00:15,  1.09s/it]Loading checkpoint shards:  13%|█▎        | 2/15 [00:02<00:13,  1.06s/it]Loading checkpoint shards:  20%|██        | 3/15 [00:03<00:12,  1.04s/it]Loading checkpoint shards:  27%|██▋       | 4/15 [00:04<00:11,  1.02s/it]Loading checkpoint shards:  33%|███▎      | 5/15 [00:05<00:10,  1.00s/it]Loading checkpoint shards:  40%|████      | 6/15 [00:12<00:29,  3.29s/it]Loading checkpoint shards:  47%|████▋     | 7/15 [00:20<00:37,  4.74s/it]Loading checkpoint shards:  53%|█████▎    | 8/15 [00:28<00:41,  5.87s/it]Loading checkpoint shards:  60%|██████    | 9/15 [00:37<00:40,  6.77s/it]Loading checkpoint shards:  67%|██████▋   | 10/15 [00:46<00:36,  7.38s/it]Loading checkpoint shards:  73%|███████▎  | 11/15 [00:56<00:33,  8.32s/it]Loading checkpoint shards:  80%|████████  | 12/15 [01:09<00:28,  9.52s/it]Loading checkpoint shards:  87%|████████▋ | 13/15 [01:22<00:21, 10.59s/it]slurm/trec_dl20_llama.sh: line 5: 2881753 Killed                  python3 rerank.py trec_dl19 meta-llama/Llama-2-70b-hf
/gpfs/home3/drau/llm_rankers/venv/lib/python3.9/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: CUDA driver initialization failed, you might not have a CUDA gpu. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)
  return torch._C._cuda_getDeviceCount() > 0
- - - - - - - - - -  Quantization and Flash Attention  2.0 not used! - - - - - - - - - - 
Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]Loading checkpoint shards:   7%|▋         | 1/15 [00:05<01:23,  5.95s/it]Loading checkpoint shards:  13%|█▎        | 2/15 [00:11<01:15,  5.79s/it]Loading checkpoint shards:  20%|██        | 3/15 [00:17<01:08,  5.74s/it]Loading checkpoint shards:  27%|██▋       | 4/15 [00:22<01:02,  5.69s/it]Loading checkpoint shards:  33%|███▎      | 5/15 [00:28<00:56,  5.63s/it]Loading checkpoint shards:  40%|████      | 6/15 [00:33<00:49,  5.54s/it]Loading checkpoint shards:  47%|████▋     | 7/15 [00:38<00:42,  5.34s/it]Loading checkpoint shards:  53%|█████▎    | 8/15 [00:43<00:36,  5.19s/it]Loading checkpoint shards:  60%|██████    | 9/15 [00:49<00:32,  5.39s/it]Loading checkpoint shards:  67%|██████▋   | 10/15 [00:58<00:32,  6.43s/it]Loading checkpoint shards:  73%|███████▎  | 11/15 [01:08<00:30,  7.61s/it]Loading checkpoint shards:  80%|████████  | 12/15 [01:19<00:26,  8.72s/it]Loading checkpoint shards:  87%|████████▋ | 13/15 [01:32<00:20, 10.05s/it]slurm/trec_dl20_llama.sh: line 6: 2895883 Killed                  python3 rerank.py trec_dl19 meta-llama/Llama-2-70b-chat-hf
slurmstepd: error: Detected 2 oom_kill events in StepId=4202569.batch. Some of the step tasks have been OOM Killed.

JOB STATISTICS
==============
Job ID: 4202569
Cluster: snellius
User/Group: drau/drau
State: OUT_OF_MEMORY (exit code 0)
Nodes: 1
Cores per node: 36
CPU Utilized: 00:38:23
CPU Efficiency: 27.34% of 02:20:24 core-walltime
Job Wall-clock time: 00:03:54
Memory Utilized: 222.52 GB
Memory Efficiency: 92.71% of 240.00 GB
