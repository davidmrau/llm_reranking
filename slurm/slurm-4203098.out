
Tue Oct 17 23:20:23 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  | 00000000:31:00.0 Off |                  Off |
| N/A   30C    P0              50W / 400W |      4MiB / 40960MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA A100-SXM4-40GB          On  | 00000000:CA:00.0 Off |                  Off |
| N/A   30C    P0              48W / 400W |      4MiB / 40960MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]Loading checkpoint shards:   7%|▋         | 1/15 [00:13<03:10, 13.64s/it]Loading checkpoint shards:  13%|█▎        | 2/15 [00:26<02:54, 13.45s/it]Loading checkpoint shards:  20%|██        | 3/15 [00:40<02:41, 13.43s/it]Loading checkpoint shards:  27%|██▋       | 4/15 [00:54<02:29, 13.61s/it]Loading checkpoint shards:  33%|███▎      | 5/15 [01:07<02:14, 13.45s/it]Loading checkpoint shards:  40%|████      | 6/15 [01:20<02:00, 13.37s/it]Loading checkpoint shards:  47%|████▋     | 7/15 [01:33<01:46, 13.36s/it]Loading checkpoint shards:  53%|█████▎    | 8/15 [01:47<01:34, 13.50s/it]Loading checkpoint shards:  60%|██████    | 9/15 [02:01<01:20, 13.42s/it]Loading checkpoint shards:  67%|██████▋   | 10/15 [02:14<01:06, 13.36s/it]Loading checkpoint shards:  73%|███████▎  | 11/15 [02:27<00:53, 13.35s/it]Loading checkpoint shards:  80%|████████  | 12/15 [02:41<00:40, 13.49s/it]Loading checkpoint shards:  87%|████████▋ | 13/15 [02:54<00:26, 13.39s/it]Loading checkpoint shards:  93%|█████████▎| 14/15 [03:07<00:13, 13.23s/it]Loading checkpoint shards: 100%|██████████| 15/15 [03:08<00:00,  9.50s/it]Loading checkpoint shards: 100%|██████████| 15/15 [03:08<00:00, 12.55s/it]
trec_dl19
class_reranking_llama_bz_1/beir_bm25_runs_top100_trec_dl19_meta-llama_Llama-2-70b-hf
DatasetDict({
    queries: Dataset({
        features: ['_id', 'text', 'title'],
        num_rows: 43
    })
    corpus: Dataset({
        features: ['_id', 'text', 'title'],
        num_rows: 5482
    })
}) queries
  0%|          | 0/43 [00:00<?, ?it/s]100%|██████████| 43/43 [00:00<00:00, 31015.49it/s]
DatasetDict({
    queries: Dataset({
        features: ['_id', 'text', 'title'],
        num_rows: 43
    })
    corpus: Dataset({
        features: ['_id', 'text', 'title'],
        num_rows: 5482
    })
}) corpus
  0%|          | 0/5482 [00:00<?, ?it/s] 64%|██████▎   | 3491/5482 [00:00<00:00, 34898.14it/s]100%|██████████| 5482/5482 [00:00<00:00, 35036.95it/s]
  0%|          | 0/135 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
/gpfs/home3/drau/llm_rankers/venv/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/gpfs/home3/drau/llm_rankers/venv/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
  1%|          | 1/135 [00:05<13:04,  5.85s/it]  1%|▏         | 2/135 [00:10<11:50,  5.34s/it]  2%|▏         | 3/135 [00:15<11:22,  5.17s/it]  3%|▎         | 4/135 [00:20<11:01,  5.05s/it]  4%|▎         | 5/135 [00:24<10:20,  4.77s/it]  4%|▍         | 6/135 [00:30<10:44,  5.00s/it]  5%|▌         | 7/135 [00:35<10:33,  4.95s/it]  6%|▌         | 8/135 [00:40<10:23,  4.91s/it]  7%|▋         | 9/135 [00:44<10:11,  4.85s/it]  7%|▋         | 10/135 [00:48<09:38,  4.62s/it]  8%|▊         | 11/135 [00:53<09:32,  4.62s/it]  9%|▉         | 12/135 [00:57<09:16,  4.52s/it] 10%|▉         | 13/135 [01:03<09:40,  4.76s/it] 10%|█         | 14/135 [01:08<09:48,  4.86s/it] 11%|█         | 15/135 [01:12<09:33,  4.78s/it] 12%|█▏        | 16/135 [01:18<09:58,  5.03s/it] 13%|█▎        | 17/135 [01:22<09:16,  4.72s/it] 13%|█▎        | 18/135 [01:26<08:59,  4.61s/it] 14%|█▍        | 19/135 [01:30<08:36,  4.45s/it] 15%|█▍        | 20/135 [01:35<08:40,  4.53s/it] 16%|█▌        | 21/135 [01:41<09:26,  4.97s/it] 16%|█▋        | 22/135 [01:46<09:17,  4.94s/it] 17%|█▋        | 23/135 [01:52<09:37,  5.15s/it] 18%|█▊        | 24/135 [01:58<10:30,  5.68s/it] 19%|█▊        | 25/135 [02:04<10:06,  5.51s/it] 19%|█▉        | 26/135 [02:10<10:22,  5.71s/it] 20%|██        | 27/135 [02:15<10:17,  5.72s/it] 21%|██        | 28/135 [02:20<09:41,  5.44s/it] 21%|██▏       | 29/135 [02:25<09:04,  5.14s/it] 22%|██▏       | 30/135 [02:28<08:15,  4.72s/it] 23%|██▎       | 31/135 [02:33<07:55,  4.58s/it] 24%|██▎       | 32/135 [02:38<08:07,  4.73s/it] 24%|██▍       | 33/135 [02:43<08:04,  4.75s/it] 25%|██▌       | 34/135 [02:48<08:18,  4.94s/it] 26%|██▌       | 35/135 [02:53<08:15,  4.95s/it] 27%|██▋       | 36/135 [02:57<07:32,  4.57s/it] 27%|██▋       | 37/135 [03:01<07:31,  4.61s/it] 28%|██▊       | 38/135 [03:06<07:28,  4.62s/it] 29%|██▉       | 39/135 [03:11<07:27,  4.66s/it] 30%|██▉       | 40/135 [03:16<07:28,  4.72s/it] 30%|███       | 41/135 [03:21<07:48,  4.98s/it] 31%|███       | 42/135 [03:26<07:45,  5.00s/it] 32%|███▏      | 43/135 [03:31<07:28,  4.88s/it] 33%|███▎      | 44/135 [03:36<07:23,  4.88s/it] 33%|███▎      | 45/135 [03:40<07:14,  4.83s/it] 34%|███▍      | 46/135 [03:45<07:06,  4.80s/it] 35%|███▍      | 47/135 [03:49<06:41,  4.56s/it] 36%|███▌      | 48/135 [03:54<06:34,  4.53s/it] 36%|███▋      | 49/135 [03:59<06:42,  4.68s/it] 37%|███▋      | 50/135 [04:04<07:04,  5.00s/it] 38%|███▊      | 51/135 [04:10<07:14,  5.18s/it] 39%|███▊      | 52/135 [04:14<06:46,  4.90s/it] 39%|███▉      | 53/135 [04:19<06:28,  4.73s/it] 40%|████      | 54/135 [04:23<06:09,  4.56s/it] 41%|████      | 55/135 [04:27<06:08,  4.61s/it] 41%|████▏     | 56/135 [04:33<06:28,  4.92s/it] 42%|████▏     | 57/135 [04:37<06:10,  4.75s/it] 43%|████▎     | 58/135 [04:41<05:44,  4.48s/it] 44%|████▎     | 59/135 [04:45<05:30,  4.35s/it] 44%|████▍     | 60/135 [04:51<05:45,  4.61s/it] 45%|████▌     | 61/135 [04:56<05:50,  4.74s/it] 46%|████▌     | 62/135 [05:01<06:10,  5.08s/it] 47%|████▋     | 63/135 [05:06<05:56,  4.94s/it] 47%|████▋     | 64/135 [05:10<05:32,  4.69s/it] 48%|████▊     | 65/135 [05:14<05:09,  4.43s/it] 49%|████▉     | 66/135 [05:20<05:31,  4.81s/it] 50%|████▉     | 67/135 [05:25<05:44,  5.07s/it] 50%|█████     | 68/135 [05:31<05:49,  5.21s/it] 51%|█████     | 69/135 [05:36<05:32,  5.04s/it] 52%|█████▏    | 70/135 [05:40<05:14,  4.84s/it] 53%|█████▎    | 71/135 [05:44<05:00,  4.70s/it] 53%|█████▎    | 72/135 [05:49<05:01,  4.78s/it] 54%|█████▍    | 73/135 [05:54<04:50,  4.69s/it] 55%|█████▍    | 74/135 [05:58<04:40,  4.60s/it] 56%|█████▌    | 75/135 [06:03<04:33,  4.56s/it] 56%|█████▋    | 76/135 [06:08<04:41,  4.77s/it] 57%|█████▋    | 77/135 [06:13<04:38,  4.80s/it] 58%|█████▊    | 78/135 [06:18<04:33,  4.80s/it] 59%|█████▊    | 79/135 [06:22<04:19,  4.64s/it] 59%|█████▉    | 80/135 [06:26<04:07,  4.50s/it] 60%|██████    | 81/135 [06:32<04:22,  4.87s/it] 61%|██████    | 82/135 [06:36<04:10,  4.72s/it] 61%|██████▏   | 83/135 [06:41<04:02,  4.66s/it] 62%|██████▏   | 84/135 [06:45<03:47,  4.46s/it] 63%|██████▎   | 85/135 [06:51<04:12,  5.04s/it] 64%|██████▎   | 86/135 [06:56<04:09,  5.10s/it] 64%|██████▍   | 87/135 [07:01<03:55,  4.90s/it] 65%|██████▌   | 88/135 [07:06<03:52,  4.94s/it] 66%|██████▌   | 89/135 [07:10<03:45,  4.90s/it] 67%|██████▋   | 90/135 [07:15<03:33,  4.75s/it] 67%|██████▋   | 91/135 [07:21<03:43,  5.07s/it] 68%|██████▊   | 92/135 [07:25<03:27,  4.81s/it] 69%|██████▉   | 93/135 [07:30<03:24,  4.88s/it] 70%|██████▉   | 94/135 [07:35<03:19,  4.87s/it] 70%|███████   | 95/135 [07:39<03:11,  4.79s/it] 71%|███████   | 96/135 [07:46<03:23,  5.23s/it] 72%|███████▏  | 97/135 [07:50<03:09,  4.99s/it] 73%|███████▎  | 98/135 [07:55<02:59,  4.86s/it] 73%|███████▎  | 99/135 [08:00<02:54,  4.86s/it] 74%|███████▍  | 100/135 [08:05<03:01,  5.19s/it] 75%|███████▍  | 101/135 [08:10<02:48,  4.94s/it] 76%|███████▌  | 102/135 [08:15<02:45,  5.02s/it] 76%|███████▋  | 103/135 [08:19<02:29,  4.66s/it] 77%|███████▋  | 104/135 [08:24<02:27,  4.77s/it] 78%|███████▊  | 105/135 [08:29<02:26,  4.87s/it] 79%|███████▊  | 106/135 [08:34<02:21,  4.88s/it] 79%|███████▉  | 107/135 [08:39<02:19,  4.98s/it] 80%|████████  | 108/135 [08:43<02:09,  4.79s/it] 81%|████████  | 109/135 [08:48<02:05,  4.81s/it] 81%|████████▏ | 110/135 [08:53<02:01,  4.87s/it] 82%|████████▏ | 111/135 [08:58<01:54,  4.77s/it] 83%|████████▎ | 112/135 [09:02<01:42,  4.46s/it] 84%|████████▎ | 113/135 [09:06<01:35,  4.34s/it] 84%|████████▍ | 114/135 [09:11<01:35,  4.56s/it] 85%|████████▌ | 115/135 [09:16<01:33,  4.70s/it] 86%|████████▌ | 116/135 [09:21<01:30,  4.77s/it] 87%|████████▋ | 117/135 [09:25<01:22,  4.58s/it] 87%|████████▋ | 118/135 [09:30<01:19,  4.68s/it] 88%|████████▊ | 119/135 [09:35<01:17,  4.87s/it] 89%|████████▉ | 120/135 [09:39<01:07,  4.52s/it] 90%|████████▉ | 121/135 [09:44<01:04,  4.60s/it] 90%|█████████ | 122/135 [09:49<01:01,  4.72s/it] 91%|█████████ | 123/135 [09:54<00:57,  4.82s/it] 92%|█████████▏| 124/135 [09:58<00:52,  4.80s/it] 93%|█████████▎| 125/135 [10:04<00:50,  5.02s/it] 93%|█████████▎| 126/135 [10:09<00:45,  5.00s/it] 94%|█████████▍| 127/135 [10:15<00:41,  5.24s/it] 95%|█████████▍| 128/135 [10:19<00:35,  5.02s/it] 96%|█████████▌| 129/135 [10:24<00:29,  4.90s/it] 96%|█████████▋| 130/135 [10:30<00:27,  5.43s/it] 97%|█████████▋| 131/135 [10:35<00:20,  5.06s/it] 98%|█████████▊| 132/135 [10:40<00:15,  5.13s/it] 99%|█████████▊| 133/135 [10:45<00:09,  4.97s/it] 99%|█████████▉| 134/135 [10:49<00:04,  4.72s/it]100%|██████████| 135/135 [10:50<00:00,  3.81s/it]100%|██████████| 135/135 [10:50<00:00,  4.82s/it]
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
ndcg_cut_10 0.4292

JOB STATISTICS
==============
Job ID: 4203098
Cluster: snellius
User/Group: drau/drau
State: RUNNING
Nodes: 1
Cores per node: 36
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 08:44:24 core-walltime
Job Wall-clock time: 00:14:34
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 240.00 GB (240.00 GB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
