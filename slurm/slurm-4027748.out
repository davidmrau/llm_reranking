
Fri Oct  6 18:44:55 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  | 00000000:32:00.0 Off |                  Off |
| N/A   29C    P0              49W / 400W |      4MiB / 40960MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
Loading the tokenizer from the `special_tokens_map.json` and the `added_tokens.json` will be removed in `transformers 5`,  it is kept for forward compatibility, but it is recommended to update your `tokenizer_config.json` by uploading it again. You will see the new `added_tokens_decoder` attribute that will store the relevant information.
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
- - - - - - - - - -  Quantization and Flash Attention  2.0 not used! - - - - - - - - - - 
- - - - - - - - - - Using T5 model- - - - - - - - - - 
nfcorpus
  0%|          | 0/3237 [00:00<?, ?it/s]100%|██████████| 3237/3237 [00:00<00:00, 36887.30it/s]
  0%|          | 0/3633 [00:00<?, ?it/s] 86%|████████▋ | 3134/3633 [00:00<00:00, 31336.74it/s]100%|██████████| 3633/3633 [00:00<00:00, 31285.22it/s]
  0%|          | 0/115 [00:00<?, ?it/s]  1%|          | 1/115 [00:04<08:20,  4.39s/it]  2%|▏         | 2/115 [00:07<06:59,  3.71s/it]  3%|▎         | 3/115 [00:10<06:25,  3.44s/it]  3%|▎         | 4/115 [00:13<06:05,  3.29s/it]  4%|▍         | 5/115 [00:16<05:53,  3.21s/it]  5%|▌         | 6/115 [00:20<05:49,  3.21s/it]  6%|▌         | 7/115 [00:23<05:43,  3.18s/it]  7%|▋         | 8/115 [00:26<05:36,  3.14s/it]  8%|▊         | 9/115 [00:29<05:30,  3.12s/it]  9%|▊         | 10/115 [00:32<05:30,  3.15s/it] 10%|▉         | 11/115 [00:35<05:25,  3.13s/it] 10%|█         | 12/115 [00:38<05:20,  3.11s/it] 11%|█▏        | 13/115 [00:41<05:16,  3.10s/it] 12%|█▏        | 14/115 [00:44<05:14,  3.11s/it] 13%|█▎        | 15/115 [00:48<05:11,  3.12s/it] 14%|█▍        | 16/115 [00:51<05:07,  3.11s/it] 15%|█▍        | 17/115 [00:54<05:02,  3.09s/it] 16%|█▌        | 18/115 [00:57<05:02,  3.12s/it] 17%|█▋        | 19/115 [01:00<05:00,  3.13s/it] 17%|█▋        | 20/115 [01:03<04:54,  3.10s/it] 18%|█▊        | 21/115 [01:06<04:51,  3.10s/it] 19%|█▉        | 22/115 [01:09<04:51,  3.13s/it] 20%|██        | 23/115 [01:12<04:48,  3.14s/it] 21%|██        | 24/115 [01:16<04:43,  3.11s/it] 22%|██▏       | 25/115 [01:19<04:38,  3.10s/it] 23%|██▎       | 26/115 [01:22<04:37,  3.12s/it] 23%|██▎       | 27/115 [01:25<04:33,  3.11s/it] 24%|██▍       | 28/115 [01:28<04:30,  3.10s/it] 25%|██▌       | 29/115 [01:31<04:26,  3.10s/it] 26%|██▌       | 30/115 [01:34<04:26,  3.14s/it] 27%|██▋       | 31/115 [01:37<04:23,  3.14s/it] 28%|██▊       | 32/115 [01:40<04:18,  3.11s/it] 29%|██▊       | 33/115 [01:44<04:15,  3.11s/it] 30%|██▉       | 34/115 [01:47<04:15,  3.15s/it] 30%|███       | 35/115 [01:50<04:11,  3.15s/it] 31%|███▏      | 36/115 [01:53<04:08,  3.14s/it] 32%|███▏      | 37/115 [01:56<04:03,  3.12s/it] 33%|███▎      | 38/115 [01:59<04:00,  3.12s/it] 34%|███▍      | 39/115 [02:02<03:56,  3.11s/it] 35%|███▍      | 40/115 [02:05<03:53,  3.11s/it] 36%|███▌      | 41/115 [02:09<03:50,  3.11s/it] 37%|███▋      | 42/115 [02:12<03:49,  3.14s/it] 37%|███▋      | 43/115 [02:15<03:45,  3.14s/it] 38%|███▊      | 44/115 [02:18<03:42,  3.13s/it] 39%|███▉      | 45/115 [02:21<03:38,  3.12s/it] 40%|████      | 46/115 [02:24<03:38,  3.17s/it] 41%|████      | 47/115 [02:28<03:35,  3.18s/it] 42%|████▏     | 48/115 [02:31<03:30,  3.15s/it] 43%|████▎     | 49/115 [02:34<03:27,  3.14s/it] 43%|████▎     | 50/115 [02:37<03:25,  3.16s/it] 44%|████▍     | 51/115 [02:40<03:22,  3.17s/it] 45%|████▌     | 52/115 [02:43<03:18,  3.16s/it] 46%|████▌     | 53/115 [02:46<03:15,  3.15s/it] 47%|████▋     | 54/115 [02:50<03:13,  3.17s/it] 48%|████▊     | 55/115 [02:53<03:09,  3.16s/it] 49%|████▊     | 56/115 [02:56<03:05,  3.15s/it] 50%|████▉     | 57/115 [02:59<03:01,  3.13s/it] 50%|█████     | 58/115 [03:02<03:00,  3.16s/it] 51%|█████▏    | 59/115 [03:05<02:56,  3.16s/it] 52%|█████▏    | 60/115 [03:09<02:52,  3.14s/it] 53%|█████▎    | 61/115 [03:12<02:49,  3.14s/it] 54%|█████▍    | 62/115 [03:15<02:47,  3.16s/it] 55%|█████▍    | 63/115 [03:18<02:43,  3.15s/it] 56%|█████▌    | 64/115 [03:21<02:40,  3.14s/it] 57%|█████▋    | 65/115 [03:24<02:36,  3.13s/it] 57%|█████▋    | 66/115 [03:27<02:35,  3.17s/it] 58%|█████▊    | 67/115 [03:31<02:31,  3.16s/it]slurmstepd: error: *** JOB 4027748 ON gcn39 CANCELLED AT 2023-10-06T18:49:05 ***
slurmstepd: error: container_p_join: open failed for /slurm/4027748/.ns: No such file or directory
slurmstepd: error: container_g_join(4027748): No such file or directory

JOB STATISTICS
==============
Job ID: 4027748
Cluster: snellius
User/Group: drau/drau
State: CANCELLED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:01
CPU Efficiency: 0.02% of 01:19:48 core-walltime
Job Wall-clock time: 00:04:26
Memory Utilized: 10.61 GB
Memory Efficiency: 8.85% of 120.00 GB
